{
  "$schema": "https://json-schema.org/draft/2020-12/schema",
  "$comment": "LLM provider & model seed configuration for ContextForge Gateway. Used by scripts/seed-llm-providers.sh",
  "providers": [
    {
      "name": "LiteLLM Proxy",
      "description": "LiteLLM unified proxy â€” routes to OpenAI, Anthropic, Azure, etc.",
      "provider_type": "openai_compatible",
      "api_base": "https://llms.matherly.net/v1",
      "api_key": null,
      "default_model": "gpt-5-mini",
      "default_temperature": 0.7,
      "enabled": true,
      "config": {},
      "models": [
        {
          "model_id": "gpt-5-mini",
          "model_name": "GPT-5 Mini",
          "description": "Fast, cost-effective model for general tasks",
          "supports_chat": true,
          "supports_streaming": true,
          "supports_function_calling": true,
          "supports_vision": false,
          "context_window": 128000,
          "max_output_tokens": 16384,
          "enabled": true
        },
        {
          "model_id": "gpt-5-nano",
          "model_name": "GPT-5 Nano",
          "description": "Ultra-fast, lowest-cost model for simple tasks",
          "supports_chat": true,
          "supports_streaming": true,
          "supports_function_calling": true,
          "supports_vision": false,
          "context_window": 128000,
          "max_output_tokens": 16384,
          "enabled": true
        },
        {
          "model_id": "text-embedding-3-small",
          "model_name": "Text Embedding 3 Small",
          "description": "OpenAI embedding model for vector search",
          "supports_chat": false,
          "supports_streaming": false,
          "supports_function_calling": false,
          "supports_vision": false,
          "context_window": 8191,
          "enabled": true
        }
      ]
    }
  ]
}
